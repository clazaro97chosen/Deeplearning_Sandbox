{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "np.random.seed(23)\n",
    "tf.random.set_seed(23)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self,units=30,activation = \"relu\", **kwargs):\n",
    "        self.__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden1 = keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self,inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring a Model\n",
    "model.save()\n",
    "keras.model.load_model(\"\") # only workds for models with Sequential or Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CallBacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The fit() method accepts a callbacks argument that lets you specify a list of objects\n",
    "that Keras will call at the start and end of training, at the start and end of each epoch,\n",
    "and even before and after processing each batch</p>\n",
    "<br>\n",
    "<p>\n",
    "You can combine both callbacks to save checkpoints of your\n",
    "model (in case your computer crashes) and interrupt training early when there is no\n",
    "more progress (to avoid wasting time and resources)\n",
    "</p>\n",
    "\n",
    "```python\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "```\n",
    "\n",
    "Write custom callbacks\n",
    "As you might expect, you can implement on_train_begin(), on_train_end(),\n",
    "on_epoch_begin(), on_epoch_end(), on_batch_begin(), and on_batch_end(). Callbacks\n",
    "can also be used during evaluation and predictions, should you ever need them\n",
    "(e.g., for debugging). For evaluation, you should implement on_test_begin(),\n",
    "on_test_end(), on_test_batch_begin(), or on_test_batch_end() (called by evaluate()), and for prediction you should implement on_predict_begin(), on_predict_end(), on_predict_batch_begin(), or on_predict_batch_end() (called by\n",
    "predict()).\n",
    "\n",
    "```python\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "checkpoint_filepath = './jupyter_images/acheck'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid),callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorboard for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 11610 samples, validate on 3870 samples\nEpoch 1/20\n11610/11610 [==============================] - 1s 74us/sample - loss: 0.4269 - val_loss: 0.3952\nEpoch 2/20\n11610/11610 [==============================] - 1s 69us/sample - loss: 0.4248 - val_loss: 0.4061\nEpoch 3/20\n11610/11610 [==============================] - 1s 65us/sample - loss: 0.4232 - val_loss: 0.3923\nEpoch 4/20\n11610/11610 [==============================] - 1s 60us/sample - loss: 0.4216 - val_loss: 0.3909\nEpoch 5/20\n11610/11610 [==============================] - 1s 60us/sample - loss: 0.4201 - val_loss: 0.3893\nEpoch 6/20\n11610/11610 [==============================] - 1s 64us/sample - loss: 0.4186 - val_loss: 0.3876\nEpoch 7/20\n11610/11610 [==============================] - 1s 58us/sample - loss: 0.4168 - val_loss: 0.3894\nEpoch 8/20\n11610/11610 [==============================] - 1s 67us/sample - loss: 0.4158 - val_loss: 0.3859\nEpoch 9/20\n11610/11610 [==============================] - 1s 63us/sample - loss: 0.4141 - val_loss: 0.3909\nEpoch 10/20\n11610/11610 [==============================] - 1s 62us/sample - loss: 0.4130 - val_loss: 0.3836\nEpoch 11/20\n11610/11610 [==============================] - 1s 58us/sample - loss: 0.4120 - val_loss: 0.3845\nEpoch 12/20\n11610/11610 [==============================] - 1s 62us/sample - loss: 0.4104 - val_loss: 0.3812\nEpoch 13/20\n11610/11610 [==============================] - 1s 57us/sample - loss: 0.4093 - val_loss: 0.3813\nEpoch 14/20\n11610/11610 [==============================] - 1s 60us/sample - loss: 0.4082 - val_loss: 0.3783\nEpoch 15/20\n11610/11610 [==============================] - 1s 59us/sample - loss: 0.4070 - val_loss: 0.3816\nEpoch 16/20\n11610/11610 [==============================] - 1s 63us/sample - loss: 0.4062 - val_loss: 0.3769\nEpoch 17/20\n11610/11610 [==============================] - 1s 69us/sample - loss: 0.4051 - val_loss: 0.3765\nEpoch 18/20\n11610/11610 [==============================] - 1s 63us/sample - loss: 0.4040 - val_loss: 0.3762\nEpoch 19/20\n11610/11610 [==============================] - 1s 63us/sample - loss: 0.4034 - val_loss: 0.3749\nEpoch 20/20\n11610/11610 [==============================] - 1s 62us/sample - loss: 0.4021 - val_loss: 0.3785\n"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir,\"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid),callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Fine Tuning Hyperparameters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange\">To use GridSearchCV or RandomizedSearchCV to expolore the hyperparameter space, we need to wrap the keras model in objects that mimic regular Scikit-Learn regressors.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate =3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\",optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14382cfd0>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid,y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test,verbose=0)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:> ## QUESTION: In relation to a models hyperparameters why is it preferable to use a randomized search rather than grid search <br>\n",
    "## ANSWER: Since there are many combinations of hyperparametrs and we want to train hundreds of variants and see which one performs best on the validation set </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 sytle=\"color:#0078d7\"> QUESTION: Why is it preferable to use a randomized search rather than a grid search for hyperparameter tuning<br> ANSWER: `RandomizedSearchCV` Because when working with neural networks we want to try many combinations of hyperparameters and see which one works best on the validation sytle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3104\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3477\n3870/3870 [==============================] - 0s 19us/sample - loss: 0.2841\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.4149\n3870/3870 [==============================] - 0s 17us/sample - loss: 0.4386\n3870/3870 [==============================] - 0s 17us/sample - loss: 0.4069\n3870/3870 [==============================] - 0s 12us/sample - loss: 0.5411\n3870/3870 [==============================] - 0s 12us/sample - loss: 0.7061\n3870/3870 [==============================] - 0s 19us/sample - loss: 0.5501\n3870/3870 [==============================] - 0s 19us/sample - loss: 0.3882\n3870/3870 [==============================] - 0s 14us/sample - loss: 0.4300\n3870/3870 [==============================] - 0s 15us/sample - loss: 0.3662\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3139\n3870/3870 [==============================] - 0s 25us/sample - loss: 0.3558\n3870/3870 [==============================] - 0s 25us/sample - loss: 0.3083\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.4238\n3870/3870 [==============================] - 0s 14us/sample - loss: 0.3989\n3870/3870 [==============================] - 0s 13us/sample - loss: 0.3675\n3870/3870 [==============================] - 0s 12us/sample - loss: 2900.4493\n3870/3870 [==============================] - 0s 15us/sample - loss: 0.9648\n3870/3870 [==============================] - 0s 14us/sample - loss: 14.8670\n3870/3870 [==============================] - 0s 17us/sample - loss: 0.3325\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3502\n3870/3870 [==============================] - 0s 15us/sample - loss: 0.3289\n3870/3870 [==============================] - 0s 17us/sample - loss: 0.3696\n3870/3870 [==============================] - 0s 17us/sample - loss: 0.4650\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3458\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3127\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.3624\n3870/3870 [==============================] - 0s 16us/sample - loss: 0.2899\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x1407023d0>,\n                   iid='warn', n_iter=10, n_jobs=None,\n                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1434abc90>,\n                                        'n_hidden': [0, 1, 2, 3],\n                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,...\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n                   return_train_score=False, scoring=None, verbose=0)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(1,100),\n",
    "    \"learning_rate\": reciprocal(3e-4,3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg,param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train,y_train,epochs=100,\n",
    "                  validation_data=(X_valid,y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-0.3140690041399536"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:yellow\">Restrict the search space and prototype will benefit from developing understanding of the hyperparameters involved in neural networks.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange;\"> Number of Hidden Layers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: Describe an example hierarchical architecture of DNN for example what would the lower-level,intermediate-leve, and high-level structures of a DNN **model** in the lower hidden layers, intermediate, and highest hidden layers respectively in the case of recognizing faces. Hint: Think hierarchial what it takes to draw a face.\n",
    "### POSSIBLE ANSWER:lower hidden layers model low-level structures (e.g., line segments of various shapes and orientations), intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g., squares, circles), and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g., faces)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: How does DNN hierarchical architecture improve their ability to generalize to new datasets. For example what parts of a tranined neural network model used to recognize faces in pictures can be used to train a new neural network to recognize hairstyles. \n",
    "### ANSWER: You can use the weights and biases of the lower layers of the already trained model this way the network will not have to learn from scracth all the low-level structures that occur in most pictures, it will only have to learn the higher-level structures (e.g., hairstyles) This is called transfer learnning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Number of Neurons per Hidden Layer</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: For the number of Neurons per hidden layer you could try increasing the number of neurons gradually until the network starts overfitting. But can you think of a more simpler time efficient approach which avoids bottleneck layers that could ruin your model?\n",
    "### POSSIBLE ANSWER: Pick a model with more layers and neurons than you actually need, then use early stopping, and other regularization techniques to prevent it from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: In general the optimal learning rate is about half of the maximum learning rate (i.e., the learning rate above which the training algorithm starts to diverge). But if you had the computational power and time how could you train a model to find a good learning rate?\n",
    "### POSSIBLE ANSWER: Ttrain the model for a few hundred iterations, starting with a very low learning rate (e.g., 10^-5) and gradually increasing it up to a very large value (e.g., 10). This is done by multiplying the learning rate by a constant factor at each iteration (e.g., by exp(log(10^6)/500) to go from 10^-5 to 10 in 500 iterations). If you plot the loss as a function of the learning rate (using a log scale for the learning rate), The optimal learning rate will be typically 10 times lower than the turning point where the loss starts to climb from previously dropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: The batch size can have a significant impact on your model's performance and training time. If Large batch sizes lead to training instabilities, especially at the beginning of training, and the resulting model may not generalize as well as a model trained with a small batch size. What strategy with the learning rate hyperparameter can be used.\n",
    "### ANSWER: As proposed by papers by Elad Hoffer et al.25 and Priya Goyal et al.26 showed that it was possible to use very large batch sizes (up to 8,192) using various techniques such as warming up the learning rate (i.e., starting training with a small learning rate, then ramping it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdeeplearningconda4784df4aecd74015b7cb859f264cd8e8",
   "display_name": "Python 3.7.7 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}